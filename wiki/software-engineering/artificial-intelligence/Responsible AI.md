---
tags: ai
---

-   Software engineers must consider the impact of their software on users and society, especially regarding ethical concerns.
-   AI systems, often based on probabilistic models, influence decisions and require careful consideration.
-   AI's human-like nature builds user trust but also poses risks of incorrect predictions and misuse.
-   Engineers should prioritize fairness, reliability, and protection from harm or discrimination in AI-enabled solutions.

# Core principles for responsible AI

1. Fair
    1. AI systems should be fair and unbiased, treating all individuals equally.
    2. For instance, in a loan approval model, it should avoid gender, ethnicity, or other biases.
    3. Fairness in AI is a research area with tools to evaluate and mitigate bias.
    4. Ensuring fairness requires considering it from the start, reviewing data for representativeness, and evaluating performance throughout development.
2. Reliability and safety
    1. AI systems must operate reliably and safely, especially in applications like autonomous vehicles and medical diagnosis.
    2. Unreliable AI systems pose significant risks to human life.
    3. Developers should subject AI-based software to rigorous testing and deployment processes.
    4. Consider the probabilistic nature of machine learning models and use confidence score thresholds when evaluating predictions for safety.
3. Privacy and security
    1. AI systems must prioritize security and privacy.
    2. Machine learning models rely on data, including personal information.
    3. Even in production, AI systems use new data, which can raise privacy and security concerns.
    4. Safeguards should be in place to protect data and customer content.
4. Inclusiveness
    1. AI systems should be inclusive and benefit everyone in society.
    2. They should not discriminate based on physical ability, gender, or other factors.
    3. Inclusiveness can be achieved by involving diverse perspectives in the design, development, and testing of AI applications.
5. Transparency
    1. AI systems should be transparent and understandable to users.
    2. Users should know the system's purpose, operation, and limitations.
    3. In the case of machine learning models, users should be informed about factors affecting prediction accuracy and confidence scores.
    4. When personal data is involved, users should understand how their data is used, retained, and who has access to it.
6. Accountability
    1. Developers are accountable for AI systems, even if they seem autonomous.
    2. Responsibility includes training models and defining decision logic.
    3. Designers and developers should follow governance and ethical standards to ensure AI systems meet legal and ethical requirements.
